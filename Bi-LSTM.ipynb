{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7062e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Embedding,Activation,Dropout,SpatialDropout1D,Bidirectional,LSTM,SimpleRNN\n",
    "from tensorflow.keras.layers import Conv1D,MaxPooling1D,GlobalAveragePooling1D,GlobalMaxPooling1D\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b46ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Starting  back at work today   Looks like it'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sugar levels dropping... munchies setting in. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@karineb22 yeah!!! have a great summer break!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>hannah montana was very good.  now going to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@Mayra326 aww, have fun!  I just had my 3D las...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0         0  Starting  back at work today   Looks like it'l...\n",
       "1         1  Sugar levels dropping... munchies setting in. ...\n",
       "2         1      @karineb22 yeah!!! have a great summer break!\n",
       "3         1  hannah montana was very good.  now going to re...\n",
       "4         1  @Mayra326 aww, have fun!  I just had my 3D las..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_file_path = 'C:/Users/gouth/Downloads/train_150k.txt'\n",
    "test_file_path = 'C:/Users/gouth/Downloads/test_62k.txt'\n",
    "\n",
    "with open(train_file_path, 'r', encoding='utf-8') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "with open(test_file_path, 'r', encoding='utf-8') as file:\n",
    "    test_data = file.readlines()\n",
    "\n",
    "\n",
    "# Splitting the data into 'sentiment' and 'text' columns\n",
    "data_split = [line.strip().split('\\t') for line in data]\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame(data_split, columns=['sentiment', 'text'])\n",
    "\n",
    "# Splitting the data into 'sentiment' and 'text' columns\n",
    "data_split = [line.strip().split('\\t') for line in test_data]\n",
    "\n",
    "# Creating a DataFrame\n",
    "test_df = pd.DataFrame(data_split, columns=['sentiment', 'text'])\n",
    "\n",
    "# Saving the DataFrame to a CSV file\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e31458e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Starting  back at work today   Looks like it'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sugar levels dropping... munchies setting in. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@karineb22 yeah!!! have a great summer break!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>hannah montana was very good.  now going to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@Mayra326 aww, have fun!  I just had my 3D las...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  Starting  back at work today   Looks like it'l...\n",
       "1          1  Sugar levels dropping... munchies setting in. ...\n",
       "2          1      @karineb22 yeah!!! have a great summer break!\n",
       "3          1  hannah montana was very good.  now going to re...\n",
       "4          1  @Mayra326 aww, have fun!  I just had my 3D las..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {'1': 1, '0': 0}\n",
    "\n",
    "df['sentiment'] = df['sentiment'].map(mapping)\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9582eeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Starting  back at work today   Looks like it'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sugar levels dropping... munchies setting in. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@karineb22 yeah!!! have a great summer break!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>hannah montana was very good.  now going to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@Mayra326 aww, have fun!  I just had my 3D las...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  Starting  back at work today   Looks like it'l...\n",
       "1          1  Sugar levels dropping... munchies setting in. ...\n",
       "2          1      @karineb22 yeah!!! have a great summer break!\n",
       "3          1  hannah montana was very good.  now going to re...\n",
       "4          1  @Mayra326 aww, have fun!  I just had my 3D las..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['sentiment'] = test_df['sentiment'].map(mapping)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d08a952a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75019\n",
       "1    74966\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa33239c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c74c8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = df['sentiment']\n",
    "label = label.to_numpy()\n",
    "type(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "667ec9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gouth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\gouth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gouth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloading nltk dependencies\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a976cb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stopwords = stopwords.words('english')\n",
    "negation = ['no','not']\n",
    "all_stopwords = [w for w in all_stopwords if w not in negation]\n",
    "\n",
    "def preprocessing(data):\n",
    "    corpus = []\n",
    "    for i in range(len(data)):\n",
    "        # remove urls\n",
    "        tweet = re.sub(r'http\\S+', ' ', data[i]) # links\n",
    "\n",
    "        # remove html tags\n",
    "        tweet = re.sub(r'<.*?>', ' ', tweet) # tags        \n",
    "        tweet = re.sub('&\\w+([-.]\\w+)*', ' ', tweet) # colorcodes\n",
    "\n",
    "        # remove digits\n",
    "        tweet = re.sub(r'\\d+', ' ', tweet)\n",
    "        tweet = re.sub('@\\w+([-.]\\w+)*', ' ', tweet) # mentions\n",
    "\n",
    "        # remove emojis\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "        tweet = emoji_pattern.sub(r'', tweet) # no emoji\n",
    "\n",
    "        # remove hashtags\n",
    "        tweet = re.sub(r'#\\w+', ' ', tweet) # hashtags\n",
    "        review = re.sub('[^a-zA-Z]', ' ', tweet) # any characters other than alphabets\n",
    "        review = review.lower() # casefolding\n",
    "        review = review.split() \n",
    "        lemma= WordNetLemmatizer() # lemmatization\n",
    "        review = [lemma.lemmatize(word) for word in review if word not in all_stopwords]\n",
    "        review = ' '.join(review)\n",
    "        corpus.append(review)\n",
    "    return corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88b03341",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = preprocessing(df['text'])\n",
    "text_test =preprocessing(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aca15dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test = test_df['sentiment']\n",
    "label_test = label_test.to_numpy()\n",
    "type(label_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val,y_train,y_val = train_test_split(text,label,test_size=0.20,stratify = label,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "412f3168",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=text_test\n",
    "y_test=label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b453de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a1c121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text data to sequences of integers\n",
    "train_sequences = token.texts_to_sequences(X_train)\n",
    "valid_sequences = token.texts_to_sequences(X_val)\n",
    "test_sequences = token.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0308a1f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52555"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(token.word_index)+1\n",
    "vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f049a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100 # specifies the maximum length of the sequences after padding or truncating.\n",
    "\n",
    "X_train = pad_sequences(train_sequences, maxlen=maxlen,padding = 'post')\n",
    "X_val = pad_sequences(valid_sequences, maxlen=maxlen,padding = 'post')\n",
    "X_test = pad_sequences(test_sequences, maxlen=maxlen,padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47f096cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119988, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "572b26cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dc5abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape\n",
    "input_shape = (100,)\n",
    "\n",
    "# Define the new parameters\n",
    "vocab_size = 60133  # Adjusted based on the input shape\n",
    "vec_size = 100  # Adjusted to match the input shape\n",
    "\n",
    "bi_lstm =Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "bi_lstm.add(Embedding(input_dim=vocab_size, output_dim=vec_size, input_length=input_shape[0], trainable=False))\n",
    "\n",
    "# LSTM\n",
    "bi_lstm.add(Bidirectional(LSTM(64, dropout=0.4, recurrent_dropout=0.4)))  # Adjusted units for the LSTM\n",
    "\n",
    "# Output layer\n",
    "bi_lstm.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8735eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_lstm.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "661d735d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 374s 97ms/step - loss: 0.6757 - accuracy: 0.5710 - val_loss: 0.6621 - val_accuracy: 0.6051\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 383s 102ms/step - loss: 0.6623 - accuracy: 0.5955 - val_loss: 0.6419 - val_accuracy: 0.6220\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 447s 119ms/step - loss: 0.6439 - accuracy: 0.6190 - val_loss: 0.6212 - val_accuracy: 0.6535\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 608s 162ms/step - loss: 0.6252 - accuracy: 0.6412 - val_loss: 0.6052 - val_accuracy: 0.6715\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 758s 202ms/step - loss: 0.6102 - accuracy: 0.6577 - val_loss: 0.5935 - val_accuracy: 0.6758\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 734s 196ms/step - loss: 0.5992 - accuracy: 0.6686 - val_loss: 0.5804 - val_accuracy: 0.6891\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 912s 243ms/step - loss: 0.5897 - accuracy: 0.6768 - val_loss: 0.5756 - val_accuracy: 0.6956\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 865s 231ms/step - loss: 0.5824 - accuracy: 0.6846 - val_loss: 0.5690 - val_accuracy: 0.6982\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 913s 243ms/step - loss: 0.5758 - accuracy: 0.6901 - val_loss: 0.5619 - val_accuracy: 0.7040\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 639s 170ms/step - loss: 0.5701 - accuracy: 0.6957 - val_loss: 0.5585 - val_accuracy: 0.7062\n"
     ]
    }
   ],
   "source": [
    "bi_lstm_history = bi_lstm.fit(X_train,y_train,epochs=10,validation_data=(X_val,y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1938/1938 [==============================] - 98s 51ms/step - loss: 0.5566 - accuracy: 0.7096\n",
      "Accuracy of the Bi-LSTN on the test set: 0.7095713019371033\n"
     ]
    }
   ],
   "source": [
    "accuracy = bi_lstm.evaluate(X_test, y_test)\n",
    "print(\"Accuracy of the Bi-LSTN on the test set:\", accuracy[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
